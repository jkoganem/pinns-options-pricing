{
  "metadata": {
    "project": "Options Pricing with PINNs",
    "version": "2.0.0",
    "last_updated": "2025-10-30",
    "description": "Validated PINN configurations for Black-Scholes option pricing"
  },

  "configurations": {
    "optimal_baseline": {
      "name": "Optimal Baseline (Production)",
      "status": "PRODUCTION",
      "description": "Best known configuration achieving 0.088% error at S=100 (ATM)",
      "date_established": "2025-10-29",
      "date_validated": "2025-10-30",
      "file_location": "src/multi_option/pinns/optimized_pinn.py",

      "performance": {
        "mean_error_pct": 0.088,
        "validation_error_pct": 0.31,
        "test_spot": 100.0,
        "test_conditions": "Single spot price (at-the-money)",
        "training_epochs": 30000,
        "training_time_minutes": 45
      },

      "hyperparameters": {
        "problem_params": {
          "K": 100.0,
          "r": 0.05,
          "q": 0.02,
          "sigma": 0.2,
          "T": 1.0
        },
        "training": {
          "n_epochs": 30000,
          "lr": 0.001,
          "n_interior": 2000,
          "n_boundary": 200,
          "n_initial": 1000
        },
        "fourier_features": {
          "use_fourier": true,
          "fourier_features": 64,
          "fourier_scale": 3.0
        },
        "warmup": {
          "use_warmup": true,
          "warmup_epochs": 1000
        },
        "ema": {
          "use_ema": true,
          "ema_decay": 0.999
        },
        "architecture": {
          "hidden_dim": 128,
          "num_layers": 5
        },
        "scheduler": {
          "type": "ReduceLROnPlateau",
          "factor": 0.5,
          "patience": 500
        },
        "early_stopping": {
          "use_early_stopping": false,
          "early_stop_patience": 2000,
          "early_stop_min_delta": 1e-6
        },
        "adaptive_weights": {
          "use_adaptive_weights": false
        }
      },

      "validation_history": [
        {
          "date": "2025-10-29",
          "method": "30K epoch training at S=100",
          "result": "0.088% error"
        },
        {
          "date": "2025-10-30",
          "method": "Optuna hyperparameter tuning (40 trials)",
          "result": "Confirmed optimal - no better config found"
        },
        {
          "date": "2025-10-30",
          "method": "Head-to-head vs Trial 17 (30K epochs)",
          "result": "Winner by 3.6x (0.31% vs 1.11%)"
        }
      ],

      "research_notes": [
        "Achieved through iterative improvements:",
        "1. Baseline SimplePINN: ~5-10% error",
        "2. + Fourier Features (σ=3.0, 64 features): ~1-2% error",
        "3. + Learning Rate Warmup (1K epochs): ~0.5% error",
        "4. + EMA (decay=0.999): ~0.1% error",
        "5. + Extended training (30K epochs): 0.088% error",
        "",
        "What worked:",
        " Fourier features (σ=3.0) - critical for high-frequency learning",
        " Learning rate warmup (1K epochs) - stable early training",
        " EMA (decay=0.999) - smooth convergence",
        " ReduceLROnPlateau scheduler - automatic fine-tuning",
        " 5 layers with 128 units - optimal capacity",
        "",
        "What didn't work:",
        " Curriculum learning (discrete/smooth): catastrophic spikes (967% error)",
        " Adaptive loss weights: marginal benefit, added complexity",
        " Higher learning rate (0.002): instability, worse convergence",
        " Fewer layers (4): reduced capacity hurts performance"
      ]
    },

    "optuna_best": {
      "name": "Trial 17 (Optuna Best)",
      "status": "EXPERIMENTAL",
      "description": "Best from hyperparameter tuning, but underperforms baseline in validation",
      "date_found": "2025-10-30",
      "experiment": "hyperparameter_tuning_optuna_fast",

      "performance": {
        "mean_error_pct": 0.1210,
        "max_error_pct": 0.3568,
        "validation_error_pct": 1.11,
        "test_spots": [80.0, 90.0, 100.0, 110.0, 120.0],
        "test_conditions": "5 spot prices (OTM, ATM, ITM)",
        "training_epochs": 10000,
        "training_time_seconds": 266.0,
        "stopped_early": false
      },

      "hyperparameters": {
        "problem_params": {
          "K": 100.0,
          "r": 0.05,
          "q": 0.02,
          "sigma": 0.2,
          "T": 1.0
        },
        "training": {
          "n_epochs": 10000,
          "lr": 0.002023,
          "n_interior": 2000,
          "n_boundary": 200,
          "n_initial": 1000
        },
        "fourier_features": {
          "use_fourier": true,
          "fourier_features": 64,
          "fourier_scale": 3.896
        },
        "warmup": {
          "use_warmup": true,
          "warmup_epochs": 800
        },
        "ema": {
          "use_ema": true,
          "ema_decay": 0.9982
        },
        "architecture": {
          "hidden_dim": 128,
          "num_layers": 4
        },
        "early_stopping": {
          "use_early_stopping": true,
          "early_stop_patience": 2000,
          "early_stop_min_delta": 1e-7
        },
        "adaptive_weights": {
          "use_adaptive_weights": false
        }
      },

      "comparison_to_baseline": {
        "fourier_scale": "30% higher (3.90 vs 3.0)",
        "fourier_features": "Same (64)",
        "learning_rate": "2.02x higher (0.00202 vs 0.001)",
        "warmup_epochs": "20% lower (800 vs 1000)",
        "ema_decay": "Slightly lower (0.9982 vs 0.999)",
        "hidden_dim": "Same (128)",
        "num_layers": "1 less (4 vs 5)",
        "training_epochs": "3x fewer (10K vs 30K)"
      },

      "validation_result": {
        "date": "2025-10-30",
        "method": "Fair comparison at S=100 with 30K epochs",
        "baseline_error": 0.31,
        "trial17_error": 1.11,
        "verdict": "REJECTED - Baseline is 3.6x better",
        "reason": "Higher learning rate causes instability"
      },

      "notes": [
        "Found via Optuna Bayesian optimization (TPE sampler)",
        "40 trials over 4.98 hours",
        "Best performer across 5 spots in 10K epoch trials",
        "Parameters similar to baseline - validates baseline design",
        "However, underperforms baseline at S=100 with equal training (30K epochs)",
        "Conclusion: Higher LR enables faster convergence but worse final accuracy"
      ]
    }
  },

  "recommendations": {
    "production": "optimal_baseline",
    "quick_training": "optuna_best with 10K epochs for faster experiments",
    "best_accuracy": "optimal_baseline with 30K epochs",
    "
": {
      "config": "optimal_baseline",
      "epochs": 30000,
      "expected_error": "0.088-0.31% at S=100",
      "training_time": "~45 minutes",
      "use_case": "Production pricing, research baseline"
    }
  },

  "hyperparameter_importance": {
    "ranking": [
      {
        "rank": 1,
        "parameter": "fourier_scale",
        "importance": "CRITICAL",
        "notes": "Controls frequency bandwidth. σ=3.0 optimal for Black-Scholes."
      },
      {
        "rank": 2,
        "parameter": "learning_rate",
        "importance": "HIGH",
        "notes": "Lower is better. 0.001 > 0.002 for stability."
      },
      {
        "rank": 3,
        "parameter": "warmup_epochs",
        "importance": "HIGH",
        "notes": "Longer warmup = more stability. 1000 epochs optimal."
      },
      {
        "rank": 4,
        "parameter": "num_layers",
        "importance": "MEDIUM",
        "notes": "5 layers > 4 layers for this problem."
      },
      {
        "rank": 5,
        "parameter": "fourier_features",
        "importance": "MEDIUM",
        "notes": "64 features optimal. Diminishing returns beyond this."
      },
      {
        "rank": 6,
        "parameter": "ema_decay",
        "importance": "MEDIUM",
        "notes": "0.999 provides good smoothing without over-damping."
      }
    ]
  },

  "experimental_archive": {
    "location": "archives/hyperparameter_tuning_20251030/",
    "contents": [
      "optuna_results/ - Full 40-trial Optuna run",
      "trial17_comparison/ - Head-to-head validation results",
      "figures/ - Visualization plots"
    ]
  }
}
